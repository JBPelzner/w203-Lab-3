---
title: "Analyzing Determinants of Crime"
author: "Rowan Cassius, Michael Steckler, Julian Pelzner"
date: "12/3/2019"
output:
  pdf_document: default
  html_document: default
---

## Introduction

Understanding what causes crime is an age-long question that is well studied in economic literature. This report aims to contribute to the discussion through an analysis of crime rates of counties in North Carolina in 1987. The data we analyze contains information about crime rates and various socioeconomic, geographic and demographic factors at the county level for 91 of North Carolina's 100 counties.

This study was conducted for the reelection campaign of the Governor of North Carolina. Political consultants have identified crime as a primary voter initiative. Through our analysis we seek to understand how effective increased penalization is at combating crime and how the living conditions within a county affect instances of crime.

In this report, we provide an analysis that illuminates the determinants of crime, and we suggest policy actions that can be implemented at the local government level. The report is structured as follows:

1. First, we check for any holes in the data and clean the dataset accordingly. 2. Next we perform an exploratory analysis of the variables which we reason are the strongest proxies for the concepts we wish to study. This is then followed by fitting a baseline regression model and evaluating all classical linear model assumptions.
3. Then, we fit several more regression models to control for ommitted variables and examine the robustness of the baseline results.
4. Lastly, we generate policy suggestions according to our findings.


## Data Cleaning

Exploration of the dataset for data validity uncovered the following prolems and we took the associated actions. After these changes, the data were vetted and ready for analysis.

* 6 of the original 97 rows have all values missing. We eliminated such rows from the dataset before analysis.
* The `prbconv` variable, representing the ratio of convictions to arrests in a given county was registered as a factor. In repsonse, we cast the probability of conviction column as numeric.
* Examination of the distribution summary table uncovered that all of the data appeared within expected bounds with the exception of `prbarr`, a variable representing the probability of arrest in a given county, because the maximum value belonging to this variable is $>1$, outside the bounds of a probability. To address this we took the following course of action:

\vspace{6pt}

```{r  setup, include = FALSE}
# Dependencies
library("stargazer")
library("car")
library("ggplot2")
library("gridExtra")

# Loading Data
crime <- read.csv('crime_v2.csv')
```

```{r, echo=FALSE, results='hide'}
# Exploration:
# Missing value summary
stargazer(is.na(crime))
# Examining missing Values
crime[91:nrow(crime), ]
paste0("Number of missing values in first 92 rows: ", sum(is.na(crime[1:91,])))
# Variales Types Summary
str(crime)
```


```{r, echo=FALSE, results='hide'}
# Cleaning changes:

# Omitting NAs
crime <- na.omit(crime)

# Casting factor as numeric
crime$prbconv <- as.numeric(crime$prbconv)

# Removing year and county identifiers
crime <- crime[!names(crime) %in% c('year', 'county')]

# Casting proability of conviction as probability
crime$prbconv <- 1.0/100 * crime$prbconv
```

```{r, fig.align='center', fig.height=2.75, fig.width=4, fig.cap="Distribution of Probility of Arrest", echo=TRUE}
# Examining outlier in probability of arrest.
ggplot(crime, aes(x=prbarr)) + 
  geom_histogram(bins = 20, fill = "dodgerblue4") +
  xlab("Probability of Arrest") +
  ylab("Count")
```
\vspace{6pt}

By looking at the histogram of `prbarr`, the variable has one outlier at `r round(max(crime$prbarr), 2)`. This is puzzling because it suggests that the number of convictions in the associated county was greater then the number of arrest in 1987. Some plausible explantions for this apparent outlier include the following:

* The number of convictions includes spillover from pervious years. That is, the number of convictions includes convictions from 1986 and before while the number of arrests only includes arrests from 1987.

* The number of convictions includes spillover from neighoring counties. That is, some criminals were arrested in neighboring counties and tried in the county associated with this outlier, letting the apparent number of convictions exceed the number of arrests.

* The outlier is a mistranscription. The official who reported the figure meant to report `r round(max(crime$prbarr), 2) - 1`.

It while plausile, it is not safe to assume the outlier is a mistranscription, so we stongly speculate that it is a result of spillover either from a different year or a different county, or both. Both cases of spillover suggest that the observation containing this outlier did not come from the underlying population we intend to study: counties which each report their own crime and crime-related information exclusively in the year of 1987. On these grounds, we removed the observation containing this outlier from the analysis.

```{r, echo=FALSE}
crime <- crime[crime$prbarr <= 1.0, ]
```

\vspace{6pt}

## Exploratory Analysis

### Variable Selection

In this analysis, we seek to understand the extent to which penalizing criminal activity and living conditions interact with crime. It is necessary to choose variables representing all of the concepts we wish to study. Among all the variables in the dataset we select `crmrte`, representing the number of crimes committed per person in a given county, as the dependent variable used to measure crime. We also select `prbarr`, representing the ratio of offenses to arrests, also known as the probability of arrest, as a proxy for measuring counties' efforts to penalize crime on the street level. 

While there are other variables in the data which can argualy proxy counties' efforts to penalize crime, such as the probability of conviction (after arrest), the probability of imprisonment (after conviction), and the average prison sentence length, we choose probability of arrest because it is the most tangible form of penalty among all those available and the also first to betide an offender. Apprehsion is a county's immediate response to a criminal's offense and is necessary before the criminal can experince any other ensuing forms of penalty. Additionally, because prison sentence is a metric only based on crimes serious enough to warrant imprisonment, it does not reflect a county's effort to penalize all crimes but only the most serious subset of them. Therefore, we consider the probability of arrest to be the strongest proxy for crime penalization that is most likely to deter a criminal from committing an offense. In addition, a higher probability of arrest could indicate that the police are more effective at detaining people who commit crimes in the county.

Moreover, We hypothesize that an increased likelihood of arrest stifes crime rates, because if criminals are less likely to escape punishment after are commiting offenses, we argue that this will make them less inclined to commit the offense in the very first place. 

The variable of interest we identify as most relevant to it's living conditions is `density`, representing the the number of people per square mile in a county. We hypothesize that higher population density leads to an increase in crime rate for two main reasons:

1. In a county with a high population density, there are more vulnerable denizens per square mile for criminals to perpetrate crimes against than there there are in a county with lower density.

2. Prior research suggests that denser areas tend to make people more irritable due to increased economic competition and lack living comfortability, thus making it's people more likely to act out through ciminal behavior.

In summary, the key explanatory variables in our baseline model will be probability of arrest and density. The next figure shows the marginal distributions of crime rate and both key explanatory variables.

\vspace{6pt}

```{r, fig.align='center', fig.height=3, fig.width=9, fig.cap="Marginal Distributions of Crime Rate, Probability of Arrest and Density", echo=TRUE}
# Crime histogram
plot.crime = ggplot(crime, aes(x=crmrte)) + 
  geom_histogram(bins = 20, fill = "red3") +
  xlab("Crime Rate") + ylab("Count") + ggtitle("Crime Rate")

# Arrest Probability histogram
plot.arrest = ggplot(crime, aes(x=prbarr)) + 
  geom_histogram(bins = 20, fill = "dodgerblue4") +
  xlab("Probability of Arrest") + ylab("") + ggtitle("Probability of Arrest")

# Density histogram
plot.density = ggplot(crime, aes(x=density)) + 
  geom_histogram(bins = 20, fill = "seagreen4") +
  xlab("Density") + ylab("") + ggtitle("Density")

grid.arrange(plot.crime, plot.arrest, plot.density, nrow = 1, ncol = 3)
```

Each distribution has some right skew and a couple outliers, but this is to be expected of complex data.

\vspace{6pt}

### Bivariate Analyses

```{r, fig.height=7, fig.width=7, fig.cap="Scatter Plots of Crime against Probability of Arrest and Density", echo=FALSE}

p1 <- ggplot(crime, aes(x=prbarr, y=crmrte)) +
  geom_point() +
  geom_smooth(method="gam", color = "dodgerblue4", fill = "dodgerblue4") +
  xlab("Probability of Arrest") +
  ylab("Crime Rate") +
  ggtitle("Crime Rate and Probability of Arrest")

p2 <- ggplot(crime, aes(x=density, y=crmrte)) + 
  geom_point() +
  geom_smooth(method="gam", color = "seagreen4", fill = "seagreen4") +
  xlab("Density") +
  ylab("Crime Rate") +
  ggtitle("Crime Rate and Density")

p3 <- ggplot(crime, aes(x=prbarr, y=log(crmrte))) +
  geom_point() +
  geom_smooth(method="gam", color = "dodgerblue4", fill = "dodgerblue4") +
  xlab("Probability of Arrest") +
  ylab("Log-Crime Rate") +
  ggtitle("Log-Crime Rate and Probability of Arrest")

p4 <- ggplot(crime, aes(x=density, y=log(crmrte))) + 
  geom_point() +
  geom_smooth(method="gam", color = "seagreen4", fill = "seagreen4") +
  xlab("Density") +
  ylab("Log-Crime Rate") +
  ggtitle("Log-Crime Rate and Density")

grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```

\vspace{6pt}

The scatter plots above compare the scatter plots of crime rate with each primary explanatory variable and the scatter plots of log-crime rate with the same variables. It appears that the untransformed specifications have the strongest linear relationship with crime rate, so we will specifiy our baseline model without transforming crime rate. Refraining from transforming the response variable will enable us to directly interpret the model coefficients as the associated changes in crime rate for a single unit increase in each explanatory variable.

The first scatter plot illustrates that likelihood of arrest has a negative correlation with crime rate, supporting our hypothesis that increasing crackdown on crime is associated with a lower crime rate. The second plot supports our second hpothesis that increases in popualation density are associated with increased crime rates. 

## Baseline Model Specification. 

$$
crimerate = \beta_0 + \beta_1prbarr + \beta_2density + \epsilon
$$

```{r, echo=FALSE}
model.1 <- lm(crmrte ~ prbarr + density, data=crime)
```

\vspace{6pt}

### Assessing CLM Assumptions

1. **Linearity**

> After our bivariate exploratory analyses of crime rate with probability of arrest and crime rate with density, we chose the specification offering relationships that appear linear. However, we can argue that the model is linear no matter what because we have not yet contrained $\epsilon$.

2. **Random Sampling**

> We can infer that because there are 97 data points, out of 100 possible counties in the state, that the researchers intended to complete a census of the population of counties in the state. However, because data from a few counties was inaccessible, they limited the study to a convenience sample of the remaining counties. Since over 5% of the population was sampled, we can not reasonably argue that the data was collected from a random sample. Nonetheless, with over 90% of counties in the state represented, we can conclude that the results of our models will offer useful insights into the causal factors behind crime rate on a statewide level. We assume that the inavailability of data in some counties is not connected to the crime rates therein in any significant way.

3. **Multicollinearity** 

> To test for multicollinearity, we have calculated the inflated variance factors for all of the regressors in the first model. The variance inflation factors for both probability of arrest and density are `r round(car::vif(model.1), 2)` respectively, each of which is close to 1, so there is no problematic multicollinearity and, therefore, no perfect multicollinearity.

4. **Zero Conditional Mean**

> To examine the zero conditional mean assumption, we have plotted the residuals as a function of the fitted values. By inspection of the residuals vs fitted values plot, there is not substantial evidence of violation of the zero conditional mean assumption. The conditional mean remains close to zero but tends downward slightly as the fitted values increase.

5. **Heteroscadascity**

> By examination of the residuals vs fitted values plot, there appears to some degree of heteroscedasticity because the magnitude of the residuals taper off at both the highest and lowest fitted values. To address this, we will use heteroscedasticty robust standard errors when making inferences.

6. **Normality of Errors**

> By inspection of the residuals' normal Q-Q plot and their distribution, the error distribution suffers from a fat right tail and a short left tail. While this means the error distribution deviates from normality somewhat, the sample size of `r nrow(crime)`, which is far greater than 30, enables us to confidently invoke the central limit theorem and conclude that in spite of the errors' non-normality, we approximate the sampling distributions of the model's coefficients.


### Model Results
- Both key expanatory variables are significant at what levels
- interpret coefficients
- 

### Plausible Omitted Variables

$$ 
\begin{aligned}
response &= \beta_{interest} interest + \beta_{omitted}omitted\\
omitted &= \delta_{interest} interest + ... \\
sign(bias) &=  sign(\beta_{omitted} \times \delta_{interest}) 
\end{aligned}
$$
Plausible ommitted vaiables that may bias the effect of density include:

* Whether a county is urban
  + Urban localities are known for having crime rates than suburban and rural areas and they are also more dense. Therefore the omission of this variable is likley to have biased the effect of density on crime rate upward from zero. Because `urban` is an indicator variable in the dataset for whether a county is urban, we can control for this omitted variable directly by including urban in subsequent regression models.
* Economic inequality 
  + Economic inequlity is likely to be positively correlated with both crime rate and desnity. Therefore the omission of this variable has most likely inflated the postive effect of density on crime rate. In the absence of a metric for economic disparity such as a gini coefficient, we can mitigate the bias from this omitted variable by including variables descibing other economic conditions, such as the various wage variables and tax per capita variable that are provided in the given dataset.
* Social Cohesion.
  + Social cohesion is likely to be negatively correlated with density. In other words, denser areas may experience higher rates of social unrest. Further, the competition between neighbors in denser areas can cause distrust and social unrest. In addition, social cohesion is likely to be negatively correlated with crime rate. We expect that the more cohesive a society (county) is, the lower its crime rate will be. However, metrics for this concepts do not exist in the given dataset. To that end, future work should strive to collect more data on these metrics. Useful metrics could include level of neighbor trust, and rates of  riots, protests, and other forms of social unrest. 
* Geographic region
  + Fortunately, there exists west and central dummy variables, which proxy geographic regions in North Carolina. As such, we include these variables in our third model.

Plausible ommitted vaiables that may bias the effect of probability of arrest include:

* Police presence
  + We speculate that police presence on the street is likely to be negatively correlated with crime rate, but positively correlated with the probability of arrest. This speculation suggests that omitting police presence has inflated the negative effect of the probability of arrest on crime rate by pushing the coefficient away from zero. We can control for police presence by including the police per capital variable in subsequent models.
* 




Our first OVB concern stems from the density variable, which is an imperfect proxy for living conditions. Density fails to capture other potential determinants of crime that are associated with dense regions, such as economic inequality and social cohesion. However, metrics for these concepts do not exist in the given dataset. To that end, future work should strive to collect more data on these metrics. Useful metrics could include gini coefficients, level of neighbor trust, and rates of  riots, protests, and other forms of social unrest. These concerns are relevant for our following models as well. 


\newpage

### Model 2 Specifcation


$$
Y = \beta_0 +\beta^T X + \gamma^T Z + \epsilon
$$


```{r, echo=FALSE}
vars.2 <- c('crmrte', 'prbarr', 'density', 'polpc', 'urban')
crime.2 <- crime[, vars.2]
model.2 <- lm(crmrte ~ ., data = crime.2)
```

### Model 3 Specifcation

* wage stuff
* geographic stuff
* demographic stuff

$$
Y = \beta_0 +\beta^T X + \gamma^T Z + \theta^TW + \epsilon
$$

where W are the following columns of the dataset pertaining to wage geography and demogaphics:
```{r, echo=FALSE}
vars.3 <- c(vars.2, "taxpc", "west", "central", "pctmin80", "wcon", 
            "wtuc", "wtrd", "wfir", "wser", "wmfg", "wfed", "wsta", "wloc", 
            "mix", "pctymle")
crime.3 <- crime[, vars.3]
model.3 <- lm(crmrte ~ ., data = crime.3)
```


$$
Y = crimerate, \space
X = 
\begin{bmatrix}
prbarr\\
density
\end{bmatrix}^T
\text{ , }
Z = 
\begin{bmatrix}
urban\\
polpc
\end{bmatrix}^T
$$


\newpage

## Regression Summaries
```{r, echo=FALSE}
# Knitr cannot process latex output so the latex is below this cell
# stargazer(model.1, model.2, model.3,
#           type = "latex",
#           omit.stat = "f",
#           se = list(sqrt(diag(sandwich::vcovHC(model.1))),
#                     sqrt(diag(sandwich::vcovHC(model.2))),
#                     sqrt(diag(sandwich::vcovHC(model.3)))),
#           star.cutoffs = c(0.05, 0.01, 0.001))
```

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{3}{c}{\textit{Dependent variable:}} \\ 
\cline{2-4} 
\\[-1.8ex] & \multicolumn{3}{c}{crmrte} \\ 
\\[-1.8ex] & (1) & (2) & (3)\\ 
\hline \\[-1.8ex] 
 prbarr & $-$0.028$^{*}$ & $-$0.028$^{*}$ & $-$0.036$^{*}$ \\ 
  & (0.012) & (0.013) & (0.016) \\ 
  & & & \\ 
 density & 0.008$^{***}$ & 0.006$^{***}$ & 0.007$^{***}$ \\ 
  & (0.001) & (0.002) & (0.002) \\ 
  & & & \\ 
 polpc &  & 7.832 & 3.902 \\ 
  &  & (5.649) & (7.751) \\ 
  & & & \\ 
 urban &  & 0.005 & $-$0.002 \\ 
  &  & (0.010) & (0.010) \\ 
  & & & \\ 
 taxpc &  &  & 0.0003 \\ 
  &  &  & (0.0004) \\ 
  & & & \\ 
 west &  &  & $-$0.0004 \\ 
  &  &  & (0.007) \\ 
  & & & \\ 
 central &  &  & $-$0.002 \\ 
  &  &  & (0.005) \\ 
  & & & \\ 
 pctmin80 &  &  & 0.0003 \\ 
  &  &  & (0.0002) \\ 
  & & & \\ 
 pctymle &  &  & 0.168$^{*}$ \\ 
  &  &  & (0.076) \\ 
  & & & \\ 
 Constant & 0.030$^{***}$ & 0.019$^{*}$ & $-$0.024 \\ 
  & (0.005) & (0.008) & (0.035) \\ 
  & & & \\ 
\hline \\[-1.8ex] 
Observations & 90 & 90 & 90 \\ 
R$^{2}$ & 0.554 & 0.613 & 0.789 \\ 
Adjusted R$^{2}$ & 0.543 & 0.594 & 0.732 \\ 
Residual Std. Error & 0.013 (df = 87) & 0.012 (df = 85) & 0.010 (df = 70) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{3}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\ 
\end{tabular} 
\end{table}

\newpage

### Recommendations


### Conclusion




### Appendix
* Summary Statistics
```{r, echo=TRUE}
#Summary
stargazer(crime)


# Examining two of the probaility variables
print('Probaility of arrest summary:')
stargazer(crime[c('prbarr')])
print('Probability of conviction summary:')
stargazer(crime[c('prbconv')])
```


* CLM Assumption Plots
```{r, fig.height=3.25, fig.width=4.5, fig.cap="Baseline Models Residuals vs Fitted Values Plot", echo=TRUE, message=FALSE}
ggplot(crime, aes(x=model.1$fitted.values, y=model.1$residuals)) +
  geom_point() +
  geom_smooth() +
  xlab("Fitted Values") +
  ylab("Residuals") +
  ggtitle("Residuals vs Fitted Values")
```

```{r, fig.height=3.5, fig.width=7, fig.cap="Residuals' distribution and Normal Q-Q Plot", echo=TRUE}
residual <- data.frame(model.1$residuals)
p.resid <- ggplot(residual, 
                  aes(x=model.1.residuals)) +
  geom_histogram(bins=20) +
  xlab("Residual") +
  ggtitle("Residual Histogram")
q.resid <- ggplot(residual, aes(sample = model.1.residuals)) +
  stat_qq() + 
  stat_qq_line() +
  ggtitle("Residual Q-Q Plot")

grid.arrange(p.resid, q.resid, nrow = 1, ncol = 2)

```